
\documentclass[11pt]{article}

\usepackage[latin1]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amscd}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{url}
\usepackage[breaklinks=true,hyperref]{hyperref}
\usepackage{amssymb}
\usepackage[dvips]{color}
\usepackage{epsfig}
\usepackage{mathrsfs}

\include{header}

\newcommand{\SOE}{{\sf SO}(\exists)}
\newcommand{\FOL}{{\sf FO(LFP)}}

\begin{document}

\begin{center} \begin{LARGE} {\sc \bf Uniform Sampling from a Convex Region} \vspace{6pt}

{\sc 6.856 Final Paper, Spring 2011} \vspace{9pt}

\end{LARGE} { \Large \textsc{Brian Hamrick and Travis Hance}}

\end{center}

\section{Introduction}

~~~ We consider the problem of randomly and uniformly sampling a point from a convex region in $n$-dimensional space. This has applications, for instance, in convex optimization \cite{Dabbene}. We phrase the problem as follows: we are given a convex region $\mathcal{R}$ in the form of a \emph{membership oracle}, a black box which can determine whether any point $x$ is in $\mathcal{R}$, along with a starting point $x_0$ in $\mathcal{R}$. The task is to sample a point from the region with with a distribution as close to uniform as possible.

Here, we study three Markov chain-based methods for sampling, the \emph{ball-walking} method, the \emph{metropolis} method and the \emph{hit-and-run} method, and we see how they perform comparitively in practice. The ball-walking method is the simpler of the two. We walk around the region in the following way: from a point $x$, we choose a random point in a ball around that point. If this new point lies in the convex region, then we jump to it; otherwise, we stay at $x$. We get a Markov chain $x_0, x_1, ...$, and after sufficiently many iterations, we take the point we are at to be our random point.

The metropolis method also performs a random walk, but in a different way. Instead of sampling from a ball, it samples from a multivariate gaussian centered at the current point. As in ball-walking, it moves to that point if it lies in $\mathcal{R}$.

The hit-and-run method is yet another random walk, but it has the advantage that it is guaranteed (almost surely) to move to another point. At a point $x$, we first choose a random direction, uniformly. Now consider the two-sided line $\ell$ which goes through $x$ which goes in this direction. Choose a point uniformly randomly from $\ell\cap\mathcal{R}$, and jump to that point.

It is known that all of these transition functions have a uniform stationary distribution, and that the distributions of the Markov chain eventually converge to these uniform distributions. In theory, the hit-and-run method converges must faster: the ball-walking and metropolis methods require at least an amount of time exponential in the number of dimensions $n$ to get an approximation to the uniform distribution that is within the desired precision, whereas the hit-and-run method requires only polynomial time. However, in this paper we introduce \emph{adaptive ball-walking} and \emph{adaptive metropolis}, modifications which adjust the transition distribution in hopes of reducing the required time.

The aim of this paper is to compare the performance in practice of these methods, which we have implemented and tested on high-dimensional convex regions.

\section{Ball Walking and Metropolis}

\section{Adaptive Ball Walking and Metropolis}

\section{Hit and Run}

\section{Implementation Details}

\section{Results}

\section{Conclusion}

\pagebreak

\begin{thebibliography}{99}

\bibitem{Dabbene} Dabbene, F., ``A randomized cutting plane scheme for convex optimization," Computer-Aided Control Systems, 2008. CACSD 2008. IEEE International Conference on , vol., no., pp.120-125, 3-5 Sept. 2008.

\bibitem{Vempala} L. Lov\'asz and S. Vempala. Hit-and-Run from a corner. \emph{SIAM Journal on Computing}, 35(4):9851005, 2006.

\bibitem{Smith} R.L. Smith, \emph{Efficient Monte-Carlo procedures for generating points uniformly distributed over
bounded regions}, Oper. Res., 32 (1984), pp. 1296-1308.

\end{thebibliography}

\end{document}

